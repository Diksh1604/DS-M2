{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNC5aNQ480BaJN2oRm7Vc0x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Theoretical Answers :-**"],"metadata":{"id":"Y0dnsV4BTAyJ"}},{"cell_type":"markdown","source":["# **Ans 1:-**\n","\n","SQL and NoSQL databases are two primary types of databases, and they differ in various ways based on their structure, scalability, and use cases. Here's a comparison:\n","\n","1. Data Model\n","SQL Databases: Relational databases that store data in structured tables with rows and columns.\n","NoSQL Databases: Non-relational databases that use flexible data models like key-value pairs, documents, wide-columns, or graphs.\n","2. Schema\n","SQL Databases: Have a predefined schema with strict rules, requiring data to adhere to a structured format.\n","NoSQL Databases: Schema-less or have a dynamic schema, allowing for flexible and unstructured data storage.\n","3. Query Language\n","SQL Databases: Use Structured Query Language (SQL) for defining and manipulating data.\n","NoSQL Databases: Use various query methods, depending on the database type (e.g., MongoDB uses JSON-like queries, Cassandra uses CQL).\n","4. Scalability\n","SQL Databases: Vertically scalable (scaling by adding more resources to a single server).\n","NoSQL Databases: Horizontally scalable (scaling by adding more servers to the database cluster).\n","5. Transactions\n","SQL Databases: Strong support for ACID (Atomicity, Consistency, Isolation, Durability) transactions, ensuring data integrity.\n","NoSQL Databases: Some NoSQL databases provide eventual consistency rather than strict ACID compliance, prioritizing scalability and performance.\n","6. Performance\n","SQL Databases: May become slower with complex queries and large-scale data.\n","NoSQL Databases: Optimized for high performance with large-scale, unstructured, or semi-structured data.\n","7. Use Cases\n","SQL Databases: Best for applications requiring complex queries, data integrity, and relationships, such as banking systems and ERP systems.\n","NoSQL Databases: Ideal for real-time applications, big data, and dynamic or unstructured data, such as social media, IoT, and content management systems.\n","8. Examples\n","SQL Databases: MySQL, PostgreSQL, Oracle, SQL Server.\n","NoSQL Databases: MongoDB, Cassandra, Couchbase, Redis.\n","9. Flexibility\n","SQL Databases: Less flexible due to rigid schemas and data types.\n","NoSQL Databases: Highly flexible and adaptable to changing requirements.\n","10. Community and Tools\n","SQL Databases: Established community with mature tools and documentation.\n","NoSQL Databases: Growing community, with newer tools and diverse database options."],"metadata":{"id":"b6gn7wOrURn7"}},{"cell_type":"markdown","source":["# **Ans 2:-**\n","\n","1) Flexible Schema\n","\n","2) Scalability\n","\n","3) High Performance\n","\n","4) Rich Query Capabilities\n","\n","5) Built for Big Data"],"metadata":{"id":"Y34VPhhfURwr"}},{"cell_type":"markdown","source":["# **Ans 3:-**\n","\n","In MongoDB, a collection is a grouping of documents that share a similar purpose or type but do not require a strict schema. It is equivalent to a table in a relational database, but with more flexibility.\n","\n","Key Characteristics of Collections in MongoDB\n","* Document-Oriented\n","\n","* Schema-Free\n","\n","* Grouping Related Data\n","\n","* Naming Conventions\n","\n","* No Fixed Size\n","\n","* Indexing\n","\n","* Implicit Creation\n"],"metadata":{"id":"84xshsplURzl"}},{"cell_type":"markdown","source":["# ***Ans 4:- ***\n","\n","MongoDB ensures high availability using a feature called replication, which is implemented through replica sets. A replica set is a group of MongoDB servers that maintain the same data, providing redundancy and failover support.\n","\n","* Replica Set Components\n","\n","* Data Replication\n","\n","* Automatic Failover\n","\n","* Redundancy"],"metadata":{"id":"jUtepAf9UR4p"}},{"cell_type":"markdown","source":["# **Ans 5:-**\n","\n","Benefits of MongoDB Atlas:-\n","\n","* Multi-Cloud Support\n","\n","* High Availability\n","\n","* Scalability\n","\n","* Global Clusters\n","\n","* Performance Optimization\n","\n","* Robust Security\n","\n","* Automated Backups"],"metadata":{"id":"gwdexISNUR65"}},{"cell_type":"markdown","source":["# ***Ans 6:- ***\n","\n","**Role of Indexes in MongoDB:**\n","\n","Indexes are data structures that store a subset of a collection’s data in a way that makes it easier to search, sort, and filter efficiently. They help MongoDB locate data quickly without scanning the entire collection.\n","\n","**Indexes Improve Performance:-**\n","\n","* Faster Query Execution\n","\n","* Efficient Sorting\n","\n","* Support for Complex Queries"],"metadata":{"id":"7sfAuiRDUR-o"}},{"cell_type":"markdown","source":["# ***Ans 7:- ***\n","\n","The MongoDB aggregation pipeline is a powerful framework for performing data aggregation operations.\n","\n","## **Stages of the MongoDB Aggregation Pipeline:-**\n","\n","1)$match\n","\n","2)$project\n","\n","3)$group\n","\n","4)$sort\n","\n","5)$limit"],"metadata":{"id":"YyiwweurUSAp"}},{"cell_type":"markdown","source":["# ***Ans 8:- ***\n","\n","Sharding in MongoDB is a method of horizontal scaling that distributes data across multiple servers, known as shards.\n","\n","Sharding involves partitioning data into smaller, manageable pieces called shards, where each shard holds a subset of the data. A MongoDB sharded cluster consists of:\n","\n","*Shards\n","\n","*Config Servers\n","\n","*Query Routers"],"metadata":{"id":"p_hWYTKyUSER"}},{"cell_type":"markdown","source":["# **Ans 9:-**\n","\n","PyMongo is the official Python driver for MongoDB. It provides tools to connect, interact, and perform operations on a MongoDB database from Python applications.\n","\n","PyMongo is used for the following reasons:\n","\n","Ease of Integration\n","\n","Rich Feature Set\n","\n","Scalability\n","\n","Flexibility\n","\n","Ease of Query Execution\n","\n","Cross-Platform\n","\n","Performance\n","\n","Active Community and Support"],"metadata":{"id":"2iSBFfW8USWB"}},{"cell_type":"markdown","source":["# ***Ans 10:- ***\n","\n","ACID Properties in MongoDB are:-\n","\n","Atomicity\n","\n","Consistency\n","\n","Isolation\n","\n","Durability"],"metadata":{"id":"INKl6nvot3z2"}},{"cell_type":"markdown","source":["# **Ans 11:-**\n","\n","## **Purpose of the explain() Function**\n","\n","Understand Query Execution Plan\n","\n","Optimize Queries\n","\n","Monitor Index Usage\n","\n","Debugging Slow Queries\n"],"metadata":{"id":"PViOKbtwt4bD"}},{"cell_type":"markdown","source":["# ***Ans 12:- ***\n","\n","MongoDB provides a schema validation mechanism to ensure that the documents inserted or updated in a collection conform to a specified structure or set of rules. While MongoDB is a schema-less database.\n","\n","Schema validation in MongoDB can be implemented at the collection level using validation rules that are defined through validation expressions. These validation rules are flexible and allow you to specify conditions for fields, types, and values, ensuring that only valid data is stored.\n","\n","### **How MongoDB Handles Schema Validation:-**\n","\n","Validation Rules and Expressions\n","\n","Validation Actions\n","\n","Validation Levels\n","\n","strict\n","\n","Field Constraints\n"],"metadata":{"id":"chhiya36u5lW"}},{"cell_type":"markdown","source":["# **Ans 13:-**\n","\n","In MongoDB, a replica set is a group of MongoDB servers that maintain the same data set. Replica sets provide data redundancy and high availability by replicating data across multiple nodes. The replica set consists of primary and secondary nodes, each with distinct roles and responsibilities.\n","\n","Primary Node\n","\n","Role\n","\n","Data Handling\n","\n","Replication\n","\n","Secondary Node"],"metadata":{"id":"qavY96zhyCD6"}},{"cell_type":"markdown","source":["# **Ans 14:-**\n","\n","MongoDB provides a variety of security mechanisms to ensure the protection of data both in transit and at rest. These mechanisms are designed to prevent unauthorized access, ensure data integrity, and protect sensitive information. Below are the key security features MongoDB offers:\n","\n","1. Authentication\n","\n","2. Authorization\n","\n","3. Encryption\n","\n","4. Data Masking and Redaction\n"],"metadata":{"id":"95T3UzNcygH0"}},{"cell_type":"markdown","source":["# **Ans 15:-**\n","\n","In MongoDB, embedded documents are a type of data structure where one document is nested within another document. This is a key feature of MongoDB's document model, which stores data in a flexible, hierarchical format using BSON (Binary JSON). Embedded documents allow you to store related data together in a single document, which can improve performance by reducing the need for complex joins and queries.\n","\n"],"metadata":{"id":"oBDJJgO9zEjb"}},{"cell_type":"markdown","source":["# ***Ans 16:- ***\n","\n","Purpose of MongoDB’s $lookup stage in aggregation is :-\n","\n","The primary purpose of the $lookup stage is to enable the joining of data from different collections. In MongoDB, since it is a NoSQL database that does not support traditional relational joins, lookup provides a way to combine documents from multiple collections based on a common field, much like how SQL joins work in relational databases.\n","This allows MongoDB users to perform complex data aggregation tasks that involve related data from different collections, all within a single query."],"metadata":{"id":"k4NqpS_vz11O"}},{"cell_type":"markdown","source":["# **Ans 17:-**\n","\n","### Common use cases for MongoDB are:-\n","1. **Content Management Systems (CMS)**\n","\n","**Use Case:** Storing and managing dynamic content, such as articles, blog posts.\n","\n","2. **Real-Time Analytics and Big Data**\n","\n","**Use Case:** Collecting and analyzing large volumes of data from sensors, logs.\n","\n","3. **Internet of Things (IoT)**\n","\n","**Use Case:** Storing and managing data from IoT devices such as sensors, cameras.\n","\n","4. **Mobile Applications**\n","\n","**Use Case:** Storing user profiles, application data, and content in mobile apps.\n","\n","5. Catalog and E-commerce Systems\n","\n","Use Case: Managing product catalogs, inventories, and customer orders in e-commerce platforms.\n","\n","\n","6. **Geospatial Data**\n","\n","**Use Case:** Storing and querying geospatial data, such as locations.\n"],"metadata":{"id":"EyvnCPdW0VvU"}},{"cell_type":"markdown","source":["## **Ans 18:-**\n","\n","### **Advantages of using MongoDB for horizontal scaling:-**\n","\n","1.Sharding for Distributed Data Storage\n","\n","2. Automatic Data Distribution\n","\n","3. High Availability with Replica Sets\n","\n","4. Easy Horizontal Scaling with Minimal Disruption\n","\n","5. Load Balancing Across Shards"],"metadata":{"id":"vHlTA-5n20vr"}},{"cell_type":"markdown","source":["# ***Ans 19:- ***\n","\n","MongoDB transactions and SQL transactions both ensure data consistency and integrity in multi-step operations, but there are some key differences between them, primarily due to MongoDB’s NoSQL nature and its underlying architecture."],"metadata":{"id":"hkI3SPJM22bN"}},{"cell_type":"markdown","source":["# **Ans 20:-**\n","\n","Main differences between capped collections and regular collections are:-\n","\n","**Definition and Purpose:**\n","\n","**Capped Collections:**\n","\n","A capped collection is a special type of collection that has a fixed size. When the collection reaches its maximum size, the oldest documents are automatically removed to make space for new documents. This makes capped collections ideal for scenarios where data retention is time-based or where only the most recent data is needed, such as logging or event tracking.\n","\n","**Regular Collections:**\n","\n","A regular collection is the default type of collection in MongoDB. It has no size limit, and documents can be inserted, updated, and deleted freely. Data can accumulate in a regular collection without automatic deletion, and the collection can grow indefinitely, depending on the available disk space."],"metadata":{"id":"6H43DlFQ224v"}},{"cell_type":"markdown","source":["# **Ans 21:-**\n","\n","**Purpose of the $match Stage are:-**\n","Filtering Documents\n","\n","Efficient Querying\n","\n","Condition-based Filtering"],"metadata":{"id":"1PcRwv2323cO"}},{"cell_type":"markdown","source":["# **Ans 22:-**\n","\n","Securing access to a MongoDB database is crucial to prevent unauthorized access, ensure data integrity, and protect sensitive information. MongoDB provides a variety of security mechanisms that can be used to secure access to the database. Key methods to secure MongoDB access are:\n","\n","1. Enable Authentication\n","\n","2. Use Role-Based Access Control (RBAC)"],"metadata":{"id":"pAH_5tbQ7W09"}},{"cell_type":"markdown","source":["# **Ans 23:-**\n","\n","WiredTiger is the default storage engine used by MongoDB, introduced in version 3.0. It plays a critical role in how MongoDB stores, manages, and retrieves data. The choice of storage engine is crucial for the performance, reliability, and scalability of a MongoDB deployment.\n","\n"," **Importantance:-**\n","a)Improved Performance and Efficiency\n","\n","b)High Availability and Durability\n","\n","c)Scalability\n","\n","d)Better Resource Utilization\n","\n","e)Data Security\n","\n","f)Wide Adoption"],"metadata":{"id":"5XrXW7rE7yCk"}},{"cell_type":"markdown","source":["# ***Pratical Answers:- ***\n","\n"],"metadata":{"id":"rGCBiR_V8_xX"}},{"cell_type":"code","source":["#Ans 1\n","\n","import pandas as pd\n","import pymongo\n","\n","def load_csv_to_mongodb(csv_file, db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","\n","    df = pd.read_csv(csv_file, encoding=\"ISO-8859-1\")\n","\n","    data = df.to_dict(orient=\"records\")\n","    if data:\n","        collection.insert_many(data)\n","        print(f\"Inserted {len(data)} records into {db_name}.{collection_name}\")\n","    else:\n","        print(\"No data found in CSV file.\")\n","\n","    client.close()\n","\n","if __name__ == \"__main__\":\n","    csv_file_path = \"superstore.csv\"\n","    database_name = \"SuperstoreDB\"\n","    collection_name = \"Orders\"\n","\n","    load_csv_to_mongodb(csv_file_path, database_name, collection_name)"],"metadata":{"id":"oE8Vrxd9LEb_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ans 2\n","\n","import pandas as pd\n","import pymongo\n","\n","def load_csv_to_mongodb(csv_file, db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","\n","    df = pd.read_csv(csv_file, encoding=\"ISO-8859-1\")\n","\n","    data = df.to_dict(orient=\"records\")\n","\n","    if data:\n","        collection.insert_many(data)\n","        print(f\"Inserted {len(data)} records into {db_name}.{collection_name}\")\n","    else:\n","        print(\"No data found in CSV file.\")\n","\n","    client.close()\n","\n","def retrieve_and_print_documents(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    for doc in collection.find():\n","        print(doc)\n","\n","    client.close()\n"],"metadata":{"id":"QMdKRKlTLFYt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ans 3\n","\n","import pandas as pd\n","import pymongo\n","\n","def load_csv_to_mongodb(csv_file, db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    df = pd.read_csv(csv_file, encoding=\"ISO-8859-1\")\n","    data = df.to_dict(orient=\"records\")\n","    if data:\n","        collection.insert_many(data)\n","        print(f\"Inserted {len(data)} records into {db_name}.{collection_name}\")\n","    else:\n","        print(\"No data found in CSV file.\")\n","    client.close()\n","\n","def retrieve_and_print_documents(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    for doc in collection.find():\n","        print(doc)\n","    client.close()\n","\n","def count_documents(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    count = collection.count_documents({})\n","    print(f\"Total number of documents in {db_name}.{collection_name}: {count}\")\n","    client.close()"],"metadata":{"id":"0NnrDViPLFQc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ans 4\n","\n","import pandas as pd\n","import pymongo\n","\n","def load_csv_to_mongodb(csv_file, db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    df = pd.read_csv(csv_file, encoding=\"ISO-8859-1\")\n","    data = df.to_dict(orient=\"records\")\n","    if data:\n","        collection.insert_many(data)\n","        print(f\"Inserted {len(data)} records into {db_name}.{collection_name}\")\n","    else:\n","        print(\"No data found in CSV file.\")\n","    client.close()\n","\n","def retrieve_and_print_documents(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","\n","    for doc in collection.find():\n","        print(doc)\n","\n","    client.close()\n","\n","def count_documents(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    count = collection.count_documents({})\n","    print(f\"Total number of documents in {db_name}.{collection_name}: {count}\")\n","    client.close()\n"],"metadata":{"id":"9OIYG2KdLFD1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ans 5\n","\n","def load_csv_to_mongodb(csv_file, db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","\n","    df = pd.read_csv(csv_file, encoding=\"ISO-8859-1\")\n","    data = df.to_dict(orient=\"records\")\n","    if data:\n","        collection.insert_many(data)\n","        print(f\"Inserted {len(data)} records into {db_name}.{collection_name}\")\n","    else:\n","        print(\"No data found in Crt pandas as pd\n","imporSV file.\")\n","    client.close()\n","\n","def retrieve_and_print_documents(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","\n","    for doc in collection.find():\n","        print(doc)\n","    client.close()\n","\n","def count_documents(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    count = collection.count_documents({})\n","    print(f\"Total number of documents in {db_name}.{collection_name}: {count}\")\n","    client.close()\n","\n","def fetch_orders_from_west(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    west_orders = collection.find({\"Region\": \"West\"})\n","    for order in west_orders:\n","        print(order)\n","    client.close()\n","\n","def fetch_orders_with_high_sales(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","\n","    high_sales_orders = collection.find({\"Sales\": {\"$gt\": 500}})\n","    for order in high_sales_orders:\n","        print(order)\n","    client.close()"],"metadata":{"id":"AYnIALdJNYsb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ans 6\n","\n","import pandas as pd\n","import pymongo\n","\n","def load_csv_to_mongodb(csv_file, db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","\n","    df = pd.read_csv(csv_file, encoding=\"ISO-8859-1\")\n","    data = df.to_dict(orient=\"records\")\n","    if data:\n","        collection.insert_many(data)\n","        print(f\"Inserted {len(data)} records into {db_name}.{collection_name}\")\n","    else:\n","        print(\"No data found in CSV file.\")\n","    client.close()\n","\n","def retrieve_and_print_documents(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    for doc in collection.find():\n","        print(doc)\n","    client.close()\n","\n","def count_documents(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    count = collection.count_documents({})\n","    print(f\"Total number of documents in {db_name}.{collection_name}: {count}\")\n","    client.close()\n","\n","def fetch_orders_from_west(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    west_orders = collection.find({\"Region\": \"West\"})\n","    for order in west_orders:\n","        print(order)\n","    client.close()\n","\n","def fetch_orders_with_high_sales(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    high_sales_orders = collection.find({\"Sales\": {\"$gt\": 500}})\n","    for order in high_sales_orders:\n","        print(order)\n","    client.close()\n","\n","def fetch_top_3_orders_by_profit(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    top_profit_orders = collection.find().sort(\"Profit\", -1).limit(3)\n","    for order in top_profit_orders:\n","        print(order)\n","    client.close()"],"metadata":{"id":"o0fjSvvPNYoq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ans 7\n","\n","import pandas as pd\n","import pymongo\n","\n","def load_csv_to_mongodb(csv_file, db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    df = pd.read_csv(csv_file, encoding=\"ISO-8859-1\")\n","    data = df.to_dict(orient=\"records\")\n","    if data:\n","        collection.insert_many(data)\n","        print(f\"Inserted {len(data)} records into {db_name}.{collection_name}\")\n","    else:\n","        print(\"No data found in CSV file.\")\n","\n","    client.close()\n","\n","def retrieve_and_print_documents(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    for doc in collection.find():\n","        print(doc)\n","    client.close()\n","\n","def count_documents(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    count = collection.count_documents({})\n","    print(f\"Total number of documents in {db_name}.{collection_name}: {count}\")\n","    client.close()\n","\n","def fetch_orders_from_west(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    west_orders = collection.find({\"Region\": \"West\"})\n","    for order in west_orders:\n","        print(order)\n","    client.close()\n","\n","def fetch_orders_with_high_sales(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    high_sales_orders = collection.find({\"Sales\": {\"$gt\": 500}})\n","    for order in high_sales_orders:\n","        print(order)\n","    client.close()\n","\n","def fetch_top_3_orders_by_profit(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","\n","    top_profit_orders = collection.find().sort(\"Profit\", -1).limit(3)\n","    for order in top_profit_orders:\n","        print(order)\n","    client.close()\n","\n","def update_ship_mode(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    result = collection.update_many({\"Ship Mode\": \"First Class\"}, {\"$set\": {\"Ship Mode\": \"Premium Class\"}})\n","    print(f\"Updated {result.modified_count} documents.\")\n","    client.close()\n"],"metadata":{"id":"FFSq0VlTNYm0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ans 8\n","\n","import pandas as pd\n","import pymongo\n","\n","def load_csv_to_mongodb(csv_file, db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    df = pd.read_csv(csv_file, encoding=\"ISO-8859-1\")\n","    data = df.to_dict(orient=\"records\")\n","    if data:\n","        collection.insert_many(data)\n","        print(f\"Inserted {len(data)} records into {db_name}.{collection_name}\")\n","    else:\n","        print(\"No data found in CSV file.\")\n","    client.close()\n","\n","def retrieve_and_print_documents(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    for doc in collection.find():\n","        print(doc)\n","    client.close()\n","\n","def count_documents(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    count = collection.count_documents({})\n","    print(f\"Total number of documents in {db_name}.{collection_name}: {count}\")\n","    client.close()\n","\n","def fetch_orders_from_west(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    west_orders = collection.find({\"Region\": \"West\"})\n","    for order in west_orders:\n","        print(order)\n","    client.close()\n","\n","def fetch_orders_with_high_sales(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    high_sales_orders = collection.find({\"Sales\": {\"$gt\": 500}})\n","    for order in high_sales_orders:\n","        print(order)\n","    client.close()\n","\n","def fetch_top_3_orders_by_profit(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    top_profit_orders = collection.find().sort(\"Profit\", -1).limit(3)\n","    for order in top_profit_orders:\n","        print(order)\n","    client.close()\n","\n","def update_ship_mode(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    result = collection.update_many({\"Ship Mode\": \"First Class\"}, {\"$set\": {\"Ship Mode\": \"Premium Class\"}})\n","    print(f\"Updated {result.modified_count} documents.\")\n","    client.close()\n","\n","def delete_low_sales_orders(db_name, collection_name, mongo_uri=\"mongodb://localhost:27017/\"):\n","    client = pymongo.MongoClient(mongo_uri)\n","    db = client[db_name]\n","    collection = db[collection_name]\n","    result = collection.delete_many({\"Sales\": {\"$lt\": 50}})\n","    print(f\"Deleted {result.deleted_count} documents.\")\n","    client.close()\n"],"metadata":{"id":"kLrRqjYZNYdq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ans 9\n","\n","data = {'Region': ['North', 'South', 'East', 'North', 'West', 'East', 'South'],\n","        'Sales': [100, 200, 150, 250, 300, 50, 400]}\n","\n","df = pd.DataFrame(data)\n","total_sales_per_region = df.groupby('Region')['Sales'].sum().reset_index()\n","\n","print(total_sales_per_region)"],"metadata":{"id":"FSz5fCPnSBXd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ans 10\n","\n","import pandas as pd\n","data = {'Ship_Mode': ['Standard', 'Express', 'Standard', 'Overnight', 'Express', 'Standard']}\n","\n","df = pd.DataFrame(data)\n","distinct_ship_modes = df['Ship_Mode'].unique()\n","\n","print(distinct_ship_modes)"],"metadata":{"id":"hifY-zu4SBOO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Ans 11\n","\n","import pandas as pd\n","\n","data = {'Category': ['Electronics', 'Furniture', 'Electronics', 'Furniture', 'Clothing', 'Clothing']}\n","\n","df = pd.DataFrame(data)\n","order_count_per_category = df.groupby('Category').size().reset_index(name='Order_Count')\n","\n","print(order_count_per_category)"],"metadata":{"id":"g7uTbWIaSBDN"},"execution_count":null,"outputs":[]}]}